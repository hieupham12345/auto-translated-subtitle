{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = r\"C:\\Users\\Hieu Pham\\Downloads\\test\"\n",
    "style = 'phim điện ảnh trung quốc, tên riêng và địa điểm 100% dùng hán việt'\n",
    "target_language = 'Vietnamese' \n",
    "\n",
    "#Example\n",
    "#historical drama\n",
    "#modern drama\n",
    "#news & current affairs\n",
    "\n",
    "#The number of subtitle lines to be translated per API call. The code works stably with a value of 1.\n",
    "#However, the drawback is that it results in a large number of API calls. I’m still working on improving the translation efficiency.\n",
    "batch_size=10\n",
    "context_window=50\n",
    "concurrency = 30 #threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tách file hoàn tất: 1.srt -> C:\\Users\\Hieu Pham\\Downloads\\test\\1_timestamps.txt, C:\\Users\\Hieu Pham\\Downloads\\test\\1_subtitles.txt (Gốc đã xóa)\n"
     ]
    }
   ],
   "source": [
    "#Split the file. The purpose is for translation. You can check how the file is split to understand better. \n",
    "#Note that after splitting, the original subtitle file will be deleted to avoid code conflicts when merging. \n",
    "#You can either save two versions in separate folders or modify the code so it doesn’t delete the original file.\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "def split_srt_folder(input_folder):\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.srt'):\n",
    "            file_path = os.path.join(input_folder, file_name)\n",
    "            base_name = os.path.splitext(file_name)[0]\n",
    "            ts_file = os.path.join(input_folder, f\"{base_name}_timestamps.txt\")\n",
    "            sub_file = os.path.join(input_folder, f\"{base_name}_subtitles.txt\")\n",
    "            \n",
    "            timestamps = []\n",
    "            subtitles = []\n",
    "            \n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read().strip()\n",
    "                blocks = re.split(r'\\n\\n', content)\n",
    "                \n",
    "                for block in blocks:\n",
    "                    lines = block.split('\\n')\n",
    "                    if len(lines) >= 3:\n",
    "                        index = lines[0].strip()\n",
    "                        timestamp = lines[1].strip()\n",
    "                        subtitle_text = ' '.join(lines[2:]).strip()\n",
    "                        \n",
    "                        timestamps.append(f\"{index} {timestamp}\")\n",
    "                        subtitles.append(f\"{index} {subtitle_text}\")\n",
    "            \n",
    "            with open(ts_file, 'w', encoding='utf-8') as ts_out:\n",
    "                ts_out.write('\\n'.join(timestamps))\n",
    "            \n",
    "            with open(sub_file, 'w', encoding='utf-8') as sub_out:\n",
    "                sub_out.write('\\n'.join(subtitles))\n",
    "            \n",
    "            os.remove(file_path)\n",
    "            print(f\"Tách file hoàn tất: {file_name} -> {ts_file}, {sub_file} (Gốc đã xóa)\")\n",
    "\n",
    "split_srt_folder(input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hieu Pham\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu dịch file: 1_subtitles.txt\n",
      "--- Summary context ---\n",
      "Dựa vào 500 dòng đầu của tệp phụ đề, bối cảnh nội dung có thể được tóm tắt như sau:\n",
      "\n",
      "Câu chuyện xoay quanh Li NantIng, một chàng trai mù và là con trai của một gia đình quý tộc giàu có, đang tới để đón cô dâu mới của mình, Shen Wei Yu. Cuộc hôn nhân này được basing từ một thỏa thuận hôn nhân trước đó giữa gia đình Li và gia đình Shen. Tuy nhiên, bối cảnh trở nên phức tạp khi gia đình Shen có hai cô con gái: Shen Wei Yu (cô dâu) bị khuyết tật và hiếm khi ra ngoài, và em gái Shen Ling vẫn còn đang học đại học.\n",
      "\n",
      "Có sự phản đối và tranh cãi giữa các thành viên trong gia đình Li và Shen về cuộc hôn nhân này, với nhiều nhận xét khinh miệt từ những người xung quanh, đặc biệt về việc Li NantIng là một chàng trai mù. Trong khi đó, Shen Wei Yu cũng có những toan tính riêng, muốn lợi dụng sự kết nối với gia đình Li để củng cố địa vị của mình, mặc dù cô thực sự có cảm xúc phức tạp và không hoàn toàn hài lòng với tình huống hiện tại.\n",
      "\n",
      "Khung cảnh diễn biến trong nhiều cuộc hội thoại, với những nhân vật đưa ra ý kiến khác nhau về sự chấp nhận và định kiến, đặc biệt về Li NantIng và Shen Wei Yu. Đồng thời, có những yếu tố công nghệ như AI góp phần làm phức tạp thêm mối quan hệ và kế hoạch của các nhân vật trong gia đình, tạo nên một câu chuyện bao gồm tình yêu, sự chấp nhận và đấu tranh cho danh dự và địa vị trong xã hội.\n",
      "-----------------------\n",
      "Đã xử lý ~300/2550 dòng... (đã hoàn thành nhóm batches 1..30)\n",
      "Đã xử lý ~600/2550 dòng... (đã hoàn thành nhóm batches 31..60)\n",
      "Đã xử lý ~900/2550 dòng... (đã hoàn thành nhóm batches 61..90)\n",
      "Đã xử lý ~1200/2550 dòng... (đã hoàn thành nhóm batches 91..120)\n",
      "Đã xử lý ~1500/2550 dòng... (đã hoàn thành nhóm batches 121..150)\n",
      "Đã xử lý ~1800/2550 dòng... (đã hoàn thành nhóm batches 151..180)\n",
      "Đã xử lý ~2100/2550 dòng... (đã hoàn thành nhóm batches 181..210)\n",
      "Đã xử lý ~2400/2550 dòng... (đã hoàn thành nhóm batches 211..240)\n",
      "Đã xử lý ~2550/2550 dòng... (đã hoàn thành nhóm batches 241..255)\n",
      "Dịch xong! File đã lưu tại: C:\\Users\\Hieu Pham\\Downloads\\test\\1_subtitles_translated.txt\n",
      "Hoàn thành dịch file: 1_subtitles.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#main translation code cell\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import tempfile\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "from chat_bot import call_chatbot\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "gpt_api_key = os.environ.get(\"CHATGPT_API_KEY\")\n",
    "\n",
    "def is_translatable(line: str) -> bool:\n",
    "    s = line.strip()\n",
    "    if not s:\n",
    "        return False\n",
    "    for ch in s:\n",
    "        if ch.isalpha() or ch.isdigit():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def translate_file(\n",
    "    file_path,\n",
    "    style,\n",
    "    batch_size=1,\n",
    "    context_window=100,\n",
    "    summary_lines_count=500,\n",
    "    target_language='Vietnamese',\n",
    "    input_encoding=\"utf-8\",\n",
    "    concurrency=10,\n",
    "    max_retries=3,\n",
    "    checkpoint_dir=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Phiên bản an toàn: sau mỗi nhóm 'concurrency' batches sẽ persist:\n",
    "      - ghi vào output_file, fsync để đảm bảo dữ liệu xuống đĩa\n",
    "      - lưu checkpoint (atomic) chứa next_batch_index để resume\n",
    "    checkpoint_dir: nếu None, lưu cùng thư mục với output_file\n",
    "    \"\"\"\n",
    "\n",
    "    # clamp batch_size\n",
    "    if batch_size < 1:\n",
    "        batch_size = 1\n",
    "    if batch_size > 20:\n",
    "        batch_size = 20\n",
    "\n",
    "    dir_name = os.path.dirname(file_path) or \".\"\n",
    "    base_name = os.path.basename(file_path).rsplit('.', 1)[0]\n",
    "    output_file = os.path.join(dir_name, f\"{base_name}_translated.txt\")\n",
    "\n",
    "    if checkpoint_dir is None:\n",
    "        checkpoint_dir = dir_name\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_file = os.path.join(checkpoint_dir, f\"{base_name}_translated.checkpoint.json\")\n",
    "\n",
    "    # load lines\n",
    "    with open(file_path, \"r\", encoding=input_encoding) as f:\n",
    "        lines = f.readlines()\n",
    "    total = len(lines)\n",
    "\n",
    "    # summary context (synchronous)\n",
    "    initial_context_lines = lines[:summary_lines_count]\n",
    "    initial_context_str = \"\".join(initial_context_lines)\n",
    "    prompt_context = f\"\"\"\n",
    "    Dựa trên {summary_lines_count} dòng đầu của file subtitle dưới đây, hãy tóm tắt bối cảnh của nội dung sau đây.\n",
    "\n",
    "    Dữ liệu:\n",
    "    {initial_context_str}\n",
    "    \"\"\"\n",
    "    summary_context = call_chatbot(prompt_context, \"gpt-4o-mini\", \"chatgpt\", gpt_api_key)\n",
    "    print(\"--- Summary context ---\")\n",
    "    print(summary_context)\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    # prepare batches\n",
    "    batches = []\n",
    "    for start in range(0, total, batch_size):\n",
    "        end = min(total, start + batch_size)\n",
    "        batches.append((start, end))\n",
    "    batch_count = len(batches)\n",
    "\n",
    "    # resume: read checkpoint if exists\n",
    "    next_batch_index = 0\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        try:\n",
    "            with open(checkpoint_file, \"r\", encoding=\"utf-8\") as cf:\n",
    "                ck = json.load(cf)\n",
    "                # ck should contain next_batch (int)\n",
    "                if isinstance(ck.get(\"next_batch\"), int) and 0 <= ck[\"next_batch\"] <= batch_count:\n",
    "                    next_batch_index = ck[\"next_batch\"]\n",
    "                    print(f\"[RESUME] Found checkpoint. Starting from batch index {next_batch_index} (batch {next_batch_index+1}/{batch_count}).\")\n",
    "                else:\n",
    "                    print(\"[RESUME] Checkpoint file malformed -> ignoring and starting from 0.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[RESUME] Failed to read checkpoint ({e}) -> starting from 0.\")\n",
    "\n",
    "    # helper: atomic write checkpoint\n",
    "    def write_checkpoint(next_idx):\n",
    "        tmp = checkpoint_file + \".tmp\"\n",
    "        payload = {\"next_batch\": next_idx}\n",
    "        with open(tmp, \"w\", encoding=\"utf-8\") as t:\n",
    "            json.dump(payload, t)\n",
    "            t.flush()\n",
    "            os.fsync(t.fileno())\n",
    "        os.replace(tmp, checkpoint_file)\n",
    "\n",
    "    # helper: call for each batch (same as earlier)\n",
    "    def make_prompt_and_call(start_idx, end_idx):\n",
    "        batch_lines = lines[start_idx:end_idx]\n",
    "        batch_indices = list(range(start_idx, end_idx))\n",
    "\n",
    "        translatable_items = []\n",
    "        for idx, ln in zip(batch_indices, batch_lines):\n",
    "            if is_translatable(ln):\n",
    "                translatable_items.append((idx, ln.rstrip(\"\\n\")))\n",
    "\n",
    "        if not translatable_items:\n",
    "            out_lines = []\n",
    "            for idx in batch_indices:\n",
    "                out_lines.append(f\"{idx+1}\\t\\n\")\n",
    "            return (start_idx, \"\".join(out_lines), len(batch_indices))\n",
    "\n",
    "        half_before = max(0, (context_window - len(translatable_items)) // 2)\n",
    "        start_ctx = max(0, translatable_items[0][0] - half_before)\n",
    "        end_ctx = min(total, start_ctx + context_window)\n",
    "        if end_ctx - start_ctx < context_window:\n",
    "            start_ctx = max(0, end_ctx - context_window)\n",
    "        context_segment = \"\".join(lines[start_ctx:end_ctx])\n",
    "\n",
    "        prompt_lines = []\n",
    "        for idx, ln in translatable_items:\n",
    "            prompt_lines.append(f\"{ln}\")\n",
    "        prompt_batch = \"\\n\\n\".join(prompt_lines)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Summary (bối cảnh chung):\n",
    "        {summary_context}\n",
    "\n",
    "        Context tham khảo (khoảng {context_window} dòng, cố gắng đặt dòng/khối cần dịch ở giữa nếu có thể):\n",
    "        {context_segment}\n",
    "\n",
    "        Các dòng sau đây cần dịch sang {target_language} với phong cách \"{style}\":\n",
    "        {prompt_batch}\n",
    "\n",
    "        **Yêu cầu trả về:**\n",
    "        - Mỗi dòng dịch trả về kèm index ở đầu, sau đó là bản dịch ngắn gọn.\n",
    "        - Giữ đúng thứ tự dòng như input.\n",
    "        - Dòng nào trống hoặc chỉ có dấu câu thì bỏ qua (không dịch, không trả).\n",
    "        - Không thêm thắt, không giải thích, không kèm văn bản gốc.\n",
    "        \"\"\"\n",
    "\n",
    "        attempt = 0\n",
    "        while attempt < max_retries:\n",
    "            try:\n",
    "                translated_batch_text = call_chatbot(prompt, \"gpt-5-mini\", \"chatgpt\", gpt_api_key)\n",
    "                return (start_idx, translated_batch_text.strip() + \"\\n\", len(batch_indices))\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                wait_time = (2 ** attempt) + random.random()\n",
    "                print(f\"[WARN] Lỗi khi gọi API cho batch {start_idx+1}-{end_idx}. Attempt {attempt}/{max_retries}. Sleep {wait_time:.1f}s. Lỗi: {e}\")\n",
    "                time.sleep(wait_time)\n",
    "\n",
    "        # nếu fail -> placeholder error lines\n",
    "        err_text = \"\"\n",
    "        for idx in batch_indices:\n",
    "            err_text += f\"{idx+1}\\t[ERROR_TRANSLATION]\\n\"\n",
    "        return (start_idx, err_text, len(batch_indices))\n",
    "\n",
    "    processed = next_batch_index * batch_size  # approximate number of lines already done (for progress; approximate if last batch smaller)\n",
    "\n",
    "    # Open output file in append mode if resuming, else write mode\n",
    "    open_mode = \"a\" if next_batch_index > 0 and os.path.exists(output_file) else \"w\"\n",
    "    with open(output_file, open_mode, encoding=\"utf-8\") as f_out:\n",
    "        with ThreadPoolExecutor(max_workers=concurrency) as executor:\n",
    "            # iterate groups starting from next_batch_index\n",
    "            group_start_idx = next_batch_index\n",
    "            while group_start_idx < batch_count:\n",
    "                group_end_idx = min(batch_count, group_start_idx + concurrency)\n",
    "                group = batches[group_start_idx:group_end_idx]\n",
    "\n",
    "                futures = {}\n",
    "                for (start_idx, end_idx) in group:\n",
    "                    fut = executor.submit(make_prompt_and_call, start_idx, end_idx)\n",
    "                    futures[fut] = start_idx\n",
    "\n",
    "                # wait all\n",
    "                done, not_done = wait(futures.keys())\n",
    "                # collect results\n",
    "                results_map = {}\n",
    "                for fut in done:\n",
    "                    try:\n",
    "                        s_idx, out_text, cnt = fut.result()\n",
    "                        results_map[s_idx] = (out_text, cnt)\n",
    "                    except Exception as e:\n",
    "                        st = futures[fut]\n",
    "                        batch_len = batches[[b[0] for b in batches].index(st)][1] - st\n",
    "                        out_text = \"\"\n",
    "                        for idx in range(st, st + batch_len):\n",
    "                            out_text += f\"{idx+1}\\t[ERROR]\\n\"\n",
    "                        results_map[st] = (out_text, batch_len)\n",
    "                        print(f\"[ERROR] Future failed for batch starting at {st+1}: {e}\")\n",
    "\n",
    "                # write group results in batch order and persist\n",
    "                for (start_idx, end_idx) in group:\n",
    "                    out_text, cnt = results_map.get(start_idx, (\"\", end_idx - start_idx))\n",
    "                    f_out.write(out_text)\n",
    "                    processed += cnt\n",
    "\n",
    "                # flush + fsync to ensure durable write\n",
    "                try:\n",
    "                    f_out.flush()\n",
    "                    os.fsync(f_out.fileno())\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] fsync failed: {e}\")\n",
    "\n",
    "                # update checkpoint: next batch to process\n",
    "                next_group_batch_index = group_end_idx\n",
    "                try:\n",
    "                    write_checkpoint(next_group_batch_index)\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] Việc ghi checkpoint thất bại: {e}\")\n",
    "\n",
    "                print(f\"Đã xử lý ~{processed}/{total} dòng... (đã hoàn thành nhóm batches {group_start_idx+1}..{group_end_idx})\")\n",
    "                group_start_idx = group_end_idx\n",
    "\n",
    "    print(f\"Dịch xong! File đã lưu tại: {output_file}\")\n",
    "    # optional: remove checkpoint on full success\n",
    "    try:\n",
    "        if os.path.exists(checkpoint_file):\n",
    "            with open(checkpoint_file, \"r\", encoding=\"utf-8\") as cf:\n",
    "                ck = json.load(cf)\n",
    "                if ck.get(\"next_batch\") == batch_count:\n",
    "                    os.remove(checkpoint_file)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "def translate_folder(input_folder, style, batch_size=1, context_window=100, summary_lines_count=500, target_language='Vietnamese', concurrency=10):\n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\"Thư mục {input_folder} không tồn tại.\")\n",
    "        return\n",
    "\n",
    "    files = [f for f in os.listdir(input_folder) if f.endswith(\"subtitles.txt\")]\n",
    "    if not files:\n",
    "        print(\"Không tìm thấy file subtitles nào trong thư mục.\")\n",
    "        return\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"Bắt đầu dịch file: {file}\")\n",
    "        translate_file(file_path, style, batch_size=batch_size, context_window=context_window, summary_lines_count=summary_lines_count, target_language=target_language, concurrency=concurrency)\n",
    "        print(f\"Hoàn thành dịch file: {file}\\n\")\n",
    "        \n",
    "# Giả sử input_folder đã được định nghĩa trước đó\n",
    "translate_folder(\n",
    "    input_folder=input_folder, \n",
    "    style=style, \n",
    "    batch_size=batch_size, \n",
    "    context_window=context_window, \n",
    "    target_language=target_language,\n",
    "    concurrency=concurrency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean\n",
    "import re\n",
    "\n",
    "def clean_subtitle_file(file_path):\n",
    "    cleaned_lines = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:  # bỏ dòng trống\n",
    "                continue\n",
    "\n",
    "            # Chuẩn hóa: \"5.abc\", \"5. abc\", \"5 abc\" => \"5 abc\"\n",
    "            line = re.sub(r\"^(\\d+)\\s*\\.?\\s*\", r\"\\1 \", line)\n",
    "            cleaned_lines.append(line)\n",
    "\n",
    "    # Ghi đè file cũ\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(cleaned_lines))\n",
    "\n",
    "\n",
    "file = r\"C:\\Users\\Hieu Pham\\Downloads\\test\\1_subtitles_translated.txt\"\n",
    "clean_subtitle_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gộp file hoàn tất: C:\\Users\\Hieu Pham\\Downloads\\test\\1_merged.srt\n"
     ]
    }
   ],
   "source": [
    "#code to clean and merge the timestamp file and the translated file into a complete SRT subtitle file\n",
    "                \n",
    "def merge_srt_folder(input_folder):\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('_timestamps.txt'):\n",
    "            base_name = file_name.replace('_timestamps.txt', '')\n",
    "            ts_file = os.path.join(input_folder, file_name)\n",
    "            sub_file = os.path.join(input_folder, f\"{base_name}_subtitles_translated.txt\")\n",
    "            output_file = os.path.join(input_folder, f\"{base_name}_merged.srt\")\n",
    "\n",
    "            if os.path.exists(sub_file):\n",
    "                timestamps = {}\n",
    "                subtitles = {}\n",
    "\n",
    "                # Đọc file timestamps\n",
    "                with open(ts_file, 'r', encoding='utf-8') as ts_in:\n",
    "                    for line in ts_in:\n",
    "                        parts = line.strip().split(maxsplit=1)  # Tách tối đa 1 lần\n",
    "                        if len(parts) == 2:\n",
    "                            timestamps[parts[0]] = parts[1]\n",
    "\n",
    "                # Đọc file subtitles\n",
    "                with open(sub_file, 'r', encoding='utf-8') as sub_in:\n",
    "                    for line in sub_in:\n",
    "                        parts = line.strip().split(maxsplit=1)  # Tách tối đa 1 lần\n",
    "                        if len(parts) == 2:\n",
    "                            subtitles[parts[0]] = parts[1]\n",
    "\n",
    "                # Ghi file .srt\n",
    "                with open(output_file, 'w', encoding='utf-8') as out:\n",
    "                    for index in sorted(timestamps.keys(), key=int):\n",
    "                        timestamp = timestamps[index]\n",
    "                        subtitle = subtitles.get(index, \" \")  # Nếu không có sub, để khoảng trắng\n",
    "                        out.write(f\"{index}\\n{timestamp}\\n{subtitle}\\n\\n\")\n",
    "\n",
    "                print(f\"Gộp file hoàn tất: {output_file}\")\n",
    "\n",
    "\n",
    "\n",
    "merge_srt_folder(input_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippets are intended for fine-tuning when converting from SRT to an audio file. You can check the corresponding project in another repo of mine.\n",
    "Use with caution — testing is required first.\n",
    "Merging timestamps means combining adjacent timestamps that are too close together, in order to prevent the voice from being cut off due to subtitles being too short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xử lý file: C:\\Users\\Hieu Pham\\Downloads\\test\\1_merged.srt\n",
      "Đã xử lý và ghi đè file: C:\\Users\\Hieu Pham\\Downloads\\test\\1_merged.srt\n",
      "Hoàn tất xử lý thư mục.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import timedelta\n",
    "\n",
    "def parse_time(time_str):\n",
    "    \"\"\"Chuyển đổi chuỗi thời gian SRT sang đối tượng timedelta.\"\"\"\n",
    "    parts = re.match(r'(\\d{2}):(\\d{2}):(\\d{2}),(\\d{3})', time_str.strip())\n",
    "    if not parts:\n",
    "        raise ValueError(f\"Định dạng thời gian không hợp lệ: {time_str}\")\n",
    "    hours, minutes, seconds, milliseconds = map(int, parts.groups())\n",
    "    return timedelta(hours=hours, minutes=minutes, seconds=seconds, milliseconds=milliseconds)\n",
    "\n",
    "def format_time(td):\n",
    "    \"\"\"Chuyển đổi đối tượng timedelta sang chuỗi thời gian SRT.\"\"\"\n",
    "    if td.total_seconds() < 0:\n",
    "         return f\"00:00:00,000\" # Tránh thời gian âm trong SRT\n",
    "\n",
    "    total_seconds = td.total_seconds()\n",
    "    hours = int(total_seconds // 3600)\n",
    "    minutes = int((total_seconds % 3600) // 60)\n",
    "    seconds = int(total_seconds % 60)\n",
    "    milliseconds = int(td.microseconds // 1000)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}\"\n",
    "\n",
    "def process_srt_file(file_path, gap_ms=100):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file {file_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file {file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    subs = []\n",
    "    raw_blocks = re.split(r'\\r?\\n\\s*\\r?\\n', content.strip())\n",
    "    seq_counter = 1\n",
    "\n",
    "    for block_num, block_content in enumerate(raw_blocks):\n",
    "        if not block_content.strip():\n",
    "            continue\n",
    "\n",
    "        block_pattern = re.match(\n",
    "            r'(\\d+)\\s*\\r?\\n'\n",
    "            r'(\\d{2}:\\d{2}:\\d{2},\\d{3})\\s*-->\\s*(\\d{2}:\\d{2}:\\d{2},\\d{3})\\s*\\r?\\n?'\n",
    "            r'(.*)',\n",
    "            block_content,\n",
    "            re.DOTALL\n",
    "        )\n",
    "\n",
    "        if block_pattern:\n",
    "            original_seq = block_pattern.group(1)\n",
    "            start_time_str = block_pattern.group(2)\n",
    "            end_time_str = block_pattern.group(3)\n",
    "            text = block_pattern.group(4).strip() # .strip() quan trọng ở đây\n",
    "\n",
    "            try:\n",
    "                start_time = parse_time(start_time_str)\n",
    "                end_time = parse_time(end_time_str)\n",
    "                if end_time < start_time:\n",
    "                    # print(f\"Cảnh báo file {file_path}, sub gốc {original_seq}: end_time < start_time. Sửa end_time = start_time.\")\n",
    "                    end_time = start_time\n",
    "                \n",
    "                subs.append({\n",
    "                    'seq': str(seq_counter),\n",
    "                    'start_time': start_time,\n",
    "                    'end_time': end_time,\n",
    "                    'text': text, # text đã được .strip()\n",
    "                    'original_start_str': start_time_str,\n",
    "                })\n",
    "                seq_counter += 1\n",
    "            except ValueError as e:\n",
    "                print(f\"Lỗi khi xử lý thời gian trong file {file_path}, sub gốc {original_seq} (khối {block_num+1}): {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Cảnh báo: Không thể parse khối sub trong {file_path} (khối {block_num+1}): \\\"{block_content[:100]}...\\\"\")\n",
    "\n",
    "    if not subs:\n",
    "        print(f\"Không tìm thấy sub nào hợp lệ trong file {file_path} hoặc định dạng không đúng.\")\n",
    "        return\n",
    "\n",
    "    # Điều chỉnh end_time\n",
    "    for i in range(len(subs) - 1):\n",
    "        current_sub = subs[i]\n",
    "        next_sub = subs[i+1]\n",
    "        target_end_time = next_sub['start_time'] - timedelta(milliseconds=gap_ms)\n",
    "        if target_end_time > current_sub['start_time']:\n",
    "            current_sub['end_time'] = target_end_time\n",
    "        else:\n",
    "            current_sub['end_time'] = current_sub['start_time'] + timedelta(milliseconds=1)\n",
    "    \n",
    "    if subs:\n",
    "        last_sub = subs[-1]\n",
    "        if last_sub['end_time'] < last_sub['start_time']:\n",
    "            last_sub['end_time'] = last_sub['start_time'] + timedelta(milliseconds=1)\n",
    "\n",
    "    # Ghi đè file cũ với logic dòng trống đã sửa\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            srt_output_lines = []\n",
    "            num_subs = len(subs)\n",
    "            for i, sub_item in enumerate(subs):\n",
    "                srt_output_lines.append(f\"{sub_item['seq']}\")\n",
    "                srt_output_lines.append(f\"{sub_item['original_start_str']} --> {format_time(sub_item['end_time'])}\")\n",
    "                \n",
    "                # Thêm dòng text (có thể là chuỗi rỗng \"\", sẽ được join thành một dòng trống)\n",
    "                # sub_item['text'] đã được strip() trong quá trình parsing.\n",
    "                # Nếu text có nhiều dòng, các \\n bên trong sẽ được giữ nguyên.\n",
    "                srt_output_lines.append(sub_item['text'])\n",
    "                \n",
    "                # Thêm dòng trống separator nếu không phải sub cuối cùng\n",
    "                if i < num_subs - 1:\n",
    "                    # Luôn thêm một dòng trống làm separator chính.\n",
    "                    # Nếu sub_item['text'] là rỗng (\"\"), dòng srt_output_lines.append(sub_item['text']) ở trên\n",
    "                    # đã tạo ra dòng trống thứ nhất (cho nội dung). Dòng trống này là dòng thứ hai (separator).\n",
    "                    # Nếu sub_item['text'] có nội dung, đây sẽ là dòng trống duy nhất sau text.\n",
    "                    srt_output_lines.append(\"\") \n",
    "            \n",
    "            final_srt_string = \"\\n\".join(srt_output_lines)\n",
    "            \n",
    "            # Đảm bảo file kết thúc bằng một ký tự newline duy nhất (nếu file không rỗng)\n",
    "            if final_srt_string:\n",
    "                final_srt_string = final_srt_string.rstrip('\\r\\n') + '\\n'\n",
    "            \n",
    "            f.write(final_srt_string)\n",
    "        print(f\"Đã xử lý và ghi đè file: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi ghi file {file_path}: {e}\")\n",
    "\n",
    "def process_srt_folder(folder_path, gap_ms=100):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Lỗi: Thư mục '{folder_path}' không tồn tại.\")\n",
    "        return\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(\".srt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            print(f\"Đang xử lý file: {file_path}\")\n",
    "            process_srt_file(file_path, gap_ms)\n",
    "    print(\"Hoàn tất xử lý thư mục.\")\n",
    "\n",
    "\n",
    "desired_gap_ms = 100\n",
    "process_srt_folder(input_folder, desired_gap_ms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
