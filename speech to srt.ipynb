{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This folder contains the MP4 or MP3 files that need to be processed.\n",
    "input_folder = r\"C:\\Users\\Hieu Pham\\Downloads\\1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mp4 => mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def convert_mp4_to_mp3(folder_path):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(\"‚ùå Folder kh√¥ng t·ªìn t·∫°i.\")\n",
    "        return\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            mp4_path = os.path.join(folder_path, filename)\n",
    "            mp3_path = os.path.join(folder_path, os.path.splitext(filename)[0] + \".mp3\")\n",
    "            \n",
    "            try:\n",
    "                print(f\"üé¨ ƒêang chuy·ªÉn: {filename}\")\n",
    "                video = VideoFileClip(mp4_path)\n",
    "                video.audio.write_audiofile(mp3_path)\n",
    "                video.close()\n",
    "                print(f\"‚úÖ Ho√†n t·∫•t: {mp3_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå L·ªói khi chuy·ªÉn {filename}: {e}\")\n",
    "\n",
    "convert_mp4_to_mp3(input_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open ai mp3 to srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Load bi·∫øn m√¥i tr∆∞·ªùng n·∫øu c·∫ßn\n",
    "load_dotenv()\n",
    "gpt_api_key = os.environ.get(\"CHATGPT_API_KEY\")\n",
    "\n",
    "target_bitrate = \"32k\"\n",
    "\n",
    "#Maximum length for each SRT (automatically split). If you don‚Äôt want splitting, just set a very large number.\n",
    "chunk_length_ms = 30 * 60 * 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next 2 code cells perform the same function.\n",
    "The first version does not adjust the start time of the first subtitle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# --- C√ÅC H√ÄM X·ª¨ L√ù SRT (Gi·ªØ nguy√™n) ---\n",
    "\n",
    "def srt_time_to_ms(t):\n",
    "    \"\"\"Chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng th·ªùi gian c·ªßa SRT (h:m:s,ms) th√†nh milliseconds.\"\"\"\n",
    "    h, m, s_ms = t.split(':')\n",
    "    s, ms = s_ms.split(',')\n",
    "    return (int(h) * 3600 + int(m) * 60 + int(s)) * 1000 + int(ms)\n",
    "\n",
    "def ms_to_srt_time(ms):\n",
    "    \"\"\"Chuy·ªÉn ƒë·ªïi milliseconds th√†nh ƒë·ªãnh d·∫°ng th·ªùi gian c·ªßa SRT (h:m:s,ms).\"\"\"\n",
    "    seconds, msec = divmod(ms, 1000)\n",
    "    hours, seconds = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d},{msec:03d}\"\n",
    "\n",
    "def adjust_srt_segment(srt_text, index_offset, time_offset_ms):\n",
    "    \"\"\"ƒêi·ªÅu ch·ªânh ch·ªâ s·ªë v√† th·ªùi gian c·ªßa m·ªôt ƒëo·∫°n ph·ª• ƒë·ªÅ SRT.\"\"\"\n",
    "    segments = srt_text.strip().split('\\n\\n')\n",
    "    adjusted_segments = []\n",
    "    \n",
    "    for seg in segments:\n",
    "        lines = seg.splitlines()\n",
    "        if len(lines) < 3:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            original_index = int(lines[0])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        new_index = index_offset + original_index\n",
    "        \n",
    "        time_line = lines[1]\n",
    "        try:\n",
    "            start_time_str, _, end_time_str = time_line.split()\n",
    "        except ValueError:\n",
    "            continue\n",
    "        \n",
    "        start_ms = srt_time_to_ms(start_time_str) + time_offset_ms\n",
    "        end_ms   = srt_time_to_ms(end_time_str) + time_offset_ms\n",
    "        new_time_line = f\"{ms_to_srt_time(start_ms)} --> {ms_to_srt_time(end_ms)}\"\n",
    "        \n",
    "        new_segment = f\"{new_index}\\n{new_time_line}\\n\" + \"\\n\".join(lines[2:])\n",
    "        adjusted_segments.append(new_segment)\n",
    "    \n",
    "    return \"\\n\\n\".join(adjusted_segments)\n",
    "\n",
    "# --- H√ÄM X·ª¨ L√ù AUDIO (Gi·ªØ nguy√™n) ---\n",
    "\n",
    "def process_long_audio(file_path, \n",
    "                       chunk_length_ms=45 * 1000,\n",
    "                       target_bitrate=\"32k\"\n",
    "                      ):\n",
    "    \"\"\"\n",
    "    C·∫Øt file audio d√†i th√†nh c√°c ƒëo·∫°n nh·ªè, g·ª≠i ƒë·∫øn Whisper API v√† gh√©p k·∫øt qu·∫£ SRT l·∫°i.\n",
    "    \"\"\"\n",
    "    audio = AudioSegment.from_mp3(file_path)\n",
    "    duration_ms = len(audio)\n",
    "    print(f\"Total duration: {duration_ms / 1000:.2f} seconds\")\n",
    "    \n",
    "    srt_results = []\n",
    "    global_index_offset = 0\n",
    "    \n",
    "    for start_ms in range(0, duration_ms, chunk_length_ms):\n",
    "        end_ms = min(start_ms + chunk_length_ms, duration_ms)\n",
    "        print(f\"Processing chunk: {start_ms // 1000}s to {end_ms // 1000}s\")\n",
    "        chunk_audio = audio[start_ms:end_ms]\n",
    "        \n",
    "        with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as tmp:\n",
    "            chunk_file_path = tmp.name\n",
    "        chunk_audio.export(chunk_file_path, format=\"mp3\", bitrate=target_bitrate)\n",
    "        \n",
    "        size_bytes = os.path.getsize(chunk_file_path)\n",
    "        print(f\"  --> Exported chunk size: {size_bytes / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        if size_bytes > 25 * 1024 * 1024:\n",
    "            os.remove(chunk_file_path)\n",
    "            raise Exception(f\"Chunk is too large ({size_bytes} bytes) even at {target_bitrate}. \"\n",
    "                            \"Try reducing chunk_length_ms.\")\n",
    "        \n",
    "        with open(chunk_file_path, \"rb\") as audio_file:\n",
    "            transcript = openai.Audio.transcribe(\n",
    "                file=audio_file,\n",
    "                model=\"whisper-1\",\n",
    "                response_format=\"srt\"\n",
    "            )\n",
    "        \n",
    "        os.remove(chunk_file_path)\n",
    "        \n",
    "        adjusted_transcript = adjust_srt_segment(transcript, global_index_offset, start_ms)\n",
    "        srt_results.append(adjusted_transcript)\n",
    "        \n",
    "        num_segments = len([seg for seg in transcript.strip().split('\\n\\n') if seg.strip() != \"\"])\n",
    "        global_index_offset += num_segments\n",
    "        \n",
    "        output_dir = os.path.dirname(file_path)\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_chunk_file = os.path.join(output_dir, f\"{base_name}_chunk_{start_ms//1000}s.srt\")\n",
    "        with open(output_chunk_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(adjusted_transcript)\n",
    "        print(f\"  --> Saved chunk SRT to {output_chunk_file}\")\n",
    "\n",
    "    combined_srt = \"\\n\\n\".join(srt_results)\n",
    "    return combined_srt\n",
    "\n",
    "\n",
    "# ===== PH·∫¶N TH·ª∞C THI CH√çNH =====\n",
    "if not gpt_api_key:\n",
    "    print(\"L·ªói: Bi·∫øn m√¥i tr∆∞·ªùng CHATGPT_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p.\")\n",
    "else:\n",
    "    openai.api_key = gpt_api_key\n",
    "    print(f\"Scanning for .mp3 files in: {input_folder}\")\n",
    "\n",
    "    # L·∫∑p qua t·∫•t c·∫£ c√°c file trong th∆∞ m·ª•c ƒë·∫ßu v√†o\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(\".mp3\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            print(f\"\\n{'='*50}\\nProcessing file: {file_path}\\n{'='*50}\")\n",
    "\n",
    "            try:\n",
    "                # G·ªçi h√†m x·ª≠ l√Ω cho t·ª´ng file audio\n",
    "                final_srt = process_long_audio(\n",
    "                    file_path,\n",
    "                    chunk_length_ms=chunk_length_ms,\n",
    "                    target_bitrate=target_bitrate\n",
    "                )\n",
    "\n",
    "                # L∆∞u file SRT cu·ªëi c√πng v√†o c√πng th∆∞ m·ª•c\n",
    "                base_name = os.path.splitext(filename)[0]\n",
    "                output_file = os.path.join(input_folder, f\"{base_name}.srt\")\n",
    "                with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(final_srt)\n",
    "                print(f\"\\nSUCCESS: Full transcription for '{filename}' saved to {output_file}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\nERROR processing file {filename}: {e}\")\n",
    "                print(\"Skipping to the next file.\")\n",
    "                continue # B·ªè qua file n√†y v√† ti·∫øp t·ª•c v·ªõi file ti·∫øp theo\n",
    "\n",
    "    print(f\"\\n{'='*50}\\nAll .mp3 files have been processed.\\n{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second version has an adjustment for the start time of the first subtitle (needs re-checking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "import re # S·ª≠ d·ª•ng ƒë·ªÉ t√°ch c√°c d√≤ng trong SRT\n",
    "\n",
    "# --- C√ÅC H√ÄM X·ª¨ L√ù SRT (Gi·ªØ nguy√™n t·ª´ code g·ªëc c·ªßa b·∫°n) ---\n",
    "def srt_time_to_ms(t):\n",
    "    \"\"\"Chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng th·ªùi gian c·ªßa SRT (h:m:s,ms) th√†nh milliseconds.\"\"\"\n",
    "    h, m, s_ms = t.split(':')\n",
    "    s, ms = s_ms.split(',')\n",
    "    return (int(h) * 3600 + int(m) * 60 + int(s)) * 1000 + int(ms)\n",
    "\n",
    "def ms_to_srt_time(ms):\n",
    "    \"\"\"Chuy·ªÉn ƒë·ªïi milliseconds th√†nh ƒë·ªãnh d·∫°ng th·ªùi gian c·ªßa SRT (h:m:s,ms).\"\"\"\n",
    "    seconds, msec = divmod(ms, 1000)\n",
    "    hours, seconds = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d},{msec:03d}\"\n",
    "\n",
    "def adjust_srt_segment(srt_text, index_offset, time_offset_ms):\n",
    "    \"\"\"ƒêi·ªÅu ch·ªânh ch·ªâ s·ªë v√† th·ªùi gian c·ªßa m·ªôt ƒëo·∫°n ph·ª• ƒë·ªÅ SRT.\"\"\"\n",
    "    # (H√†m n√†y gi·ªØ nguy√™n, kh√¥ng c·∫ßn thay ƒë·ªïi)\n",
    "    segments = srt_text.strip().split('\\n\\n')\n",
    "    adjusted_segments = []\n",
    "    for seg in segments:\n",
    "        lines = seg.splitlines()\n",
    "        if len(lines) < 3: continue\n",
    "        try: original_index = int(lines[0])\n",
    "        except ValueError: continue\n",
    "        new_index = index_offset + original_index\n",
    "        time_line = lines[1]\n",
    "        try: start_time_str, _, end_time_str = time_line.split()\n",
    "        except ValueError: continue\n",
    "        start_ms = srt_time_to_ms(start_time_str) + time_offset_ms\n",
    "        end_ms   = srt_time_to_ms(end_time_str) + time_offset_ms\n",
    "        new_time_line = f\"{ms_to_srt_time(start_ms)} --> {ms_to_srt_time(end_ms)}\"\n",
    "        new_segment = f\"{new_index}\\n{new_time_line}\\n\" + \"\\n\".join(lines[2:])\n",
    "        adjusted_segments.append(new_segment)\n",
    "    return \"\\n\\n\".join(adjusted_segments)\n",
    "\n",
    "# M·ªöI: H√†m ∆∞·ªõc l∆∞·ª£ng th·ªùi l∆∞·ª£ng c·ªßa text theo y√™u c·∫ßu\n",
    "def estimate_duration_ms(text, chars_per_second=15):\n",
    "    \"\"\"\n",
    "    ∆Ø·ªõc t√≠nh th·ªùi gian (ms) c·∫ßn thi·∫øt ƒë·ªÉ ƒë·ªçc m·ªôt ƒëo·∫°n vƒÉn b·∫£n.\n",
    "    M·∫∑c ƒë·ªãnh t·ªëc ƒë·ªô ƒë·ªçc l√† 15 k√Ω t·ª±/gi√¢y.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 0\n",
    "    num_chars = len(text)\n",
    "    estimated_seconds = num_chars / chars_per_second\n",
    "    return int(estimated_seconds * 1000)\n",
    "\n",
    "# --- H√ÄM X·ª¨ L√ù AUDIO (Quay v·ªÅ code g·ªëc v√† th√™m logic m·ªõi) ---\n",
    "\n",
    "def process_long_audio(file_path, \n",
    "                       chunk_length_ms=45 * 1000,\n",
    "                       target_bitrate=\"32k\"\n",
    "                      ):\n",
    "    \"\"\"\n",
    "    C·∫Øt file audio d√†i th√†nh c√°c ƒëo·∫°n nh·ªè, g·ª≠i ƒë·∫øn Whisper API v√† gh√©p k·∫øt qu·∫£ SRT l·∫°i.\n",
    "    THAY ƒê·ªîI: Can thi·ªáp v√†o ph·ª• ƒë·ªÅ ƒë·∫ßu ti√™n ƒë·ªÉ t√≠nh to√°n l·∫°i start_ms.\n",
    "    \"\"\"\n",
    "    audio = AudioSegment.from_mp3(file_path)\n",
    "    duration_ms = len(audio)\n",
    "    print(f\"Total duration: {duration_ms / 1000:.2f} seconds\")\n",
    "    \n",
    "    srt_results = []\n",
    "    global_index_offset = 0\n",
    "    \n",
    "    for start_ms in range(0, duration_ms, chunk_length_ms):\n",
    "        end_ms = min(start_ms + chunk_length_ms, duration_ms)\n",
    "        print(f\"Processing chunk: {start_ms // 1000}s to {end_ms // 1000}s\")\n",
    "        chunk_audio = audio[start_ms:end_ms]\n",
    "        \n",
    "        with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as tmp:\n",
    "            chunk_file_path = tmp.name\n",
    "        chunk_audio.export(chunk_file_path, format=\"mp3\", bitrate=target_bitrate)\n",
    "        \n",
    "        size_bytes = os.path.getsize(chunk_file_path)\n",
    "        print(f\"  --> Exported chunk size: {size_bytes / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        if size_bytes > 25 * 1024 * 1024:\n",
    "            os.remove(chunk_file_path)\n",
    "            raise Exception(f\"Chunk is too large ({size_bytes} bytes).\")\n",
    "        \n",
    "        with open(chunk_file_path, \"rb\") as audio_file:\n",
    "            transcript = openai.Audio.transcribe(\n",
    "                file=audio_file,\n",
    "                model=\"whisper-1\",\n",
    "                response_format=\"srt\"\n",
    "            )\n",
    "        \n",
    "        os.remove(chunk_file_path)\n",
    "\n",
    "        # ===== LOGIC M·ªöI ƒê∆Ø·ª¢C TH√äM V√ÄO =====\n",
    "        # Ch·ªâ can thi·ªáp v√†o k·∫øt qu·∫£ c·ªßa chunk ƒë·∫ßu ti√™n\n",
    "        is_first_chunk = (start_ms == 0)\n",
    "        if is_first_chunk and transcript.strip():\n",
    "            print(\"  --> First chunk detected. Adjusting timestamp of the first subtitle...\")\n",
    "            # T√°ch c√°c kh·ªëi ph·ª• ƒë·ªÅ\n",
    "            segments = transcript.strip().split('\\n\\n')\n",
    "            if segments:\n",
    "                first_segment_lines = segments[0].splitlines()\n",
    "                \n",
    "                # Ph√¢n t√≠ch kh·ªëi ph·ª• ƒë·ªÅ ƒë·∫ßu ti√™n\n",
    "                if len(first_segment_lines) >= 3:\n",
    "                    time_line = first_segment_lines[1]\n",
    "                    text_lines = first_segment_lines[2:]\n",
    "                    \n",
    "                    try:\n",
    "                        # L·∫•y th·ªùi gian k·∫øt th√∫c v√† n·ªôi dung text\n",
    "                        _, _, end_time_str = time_line.split()\n",
    "                        first_sub_end_ms = srt_time_to_ms(end_time_str)\n",
    "                        first_sub_text = \" \".join(text_lines)\n",
    "                        \n",
    "                        # ∆Ø·ªõc t√≠nh th·ªùi l∆∞·ª£ng v√† t√≠nh to√°n start_ms m·ªõi\n",
    "                        estimated_dur_ms = estimate_duration_ms(first_sub_text)\n",
    "                        new_start_ms = first_sub_end_ms - estimated_dur_ms - 100 # Th√™m buffer 100ms\n",
    "                        new_start_ms = max(0, new_start_ms) # ƒê·∫£m b·∫£o kh√¥ng b·ªã √¢m\n",
    "                        \n",
    "                        print(f\"    - Original End: {first_sub_end_ms}ms, Text: \\\"{first_sub_text[:30]}...\\\"\")\n",
    "                        print(f\"    - Estimated Duration: {estimated_dur_ms}ms\")\n",
    "                        print(f\"    - New Calculated Start: {new_start_ms}ms\")\n",
    "                        \n",
    "                        # T·∫°o l·∫°i d√≤ng th·ªùi gian v√† c·∫≠p nh·∫≠t v√†o kh·ªëi ph·ª• ƒë·ªÅ\n",
    "                        new_start_time_str = ms_to_srt_time(new_start_ms)\n",
    "                        new_time_line = f\"{new_start_time_str} --> {end_time_str}\"\n",
    "                        first_segment_lines[1] = new_time_line\n",
    "                        \n",
    "                        # Gh√©p l·∫°i kh·ªëi ph·ª• ƒë·ªÅ ƒë·∫ßu ti√™n v√† to√†n b·ªô transcript\n",
    "                        segments[0] = \"\\n\".join(first_segment_lines)\n",
    "                        transcript = \"\\n\\n\".join(segments)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"    - Could not adjust first subtitle: {e}\")\n",
    "\n",
    "        # ======================================\n",
    "\n",
    "        adjusted_transcript = adjust_srt_segment(transcript, global_index_offset, start_ms)\n",
    "        srt_results.append(adjusted_transcript)\n",
    "        \n",
    "        num_segments = len([seg for seg in transcript.strip().split('\\n\\n') if seg.strip() != \"\"])\n",
    "        global_index_offset += num_segments\n",
    "\n",
    "    combined_srt = \"\\n\\n\".join(srt_results)\n",
    "    return combined_srt\n",
    "\n",
    "# ===== PH·∫¶N TH·ª∞C THI CH√çNH (Gi·ªØ nguy√™n) =====\n",
    "# (B·∫°n c√≥ th·ªÉ ch·∫°y ph·∫ßn n√†y nh∆∞ c≈©)\n",
    "\n",
    "# ===== PH·∫¶N TH·ª∞C THI CH√çNH =====\n",
    "if not gpt_api_key:\n",
    "    print(\"L·ªói: Bi·∫øn m√¥i tr∆∞·ªùng CHATGPT_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p.\")\n",
    "else:\n",
    "    openai.api_key = gpt_api_key\n",
    "    print(f\"Scanning for .mp3 files in: {input_folder}\")\n",
    "\n",
    "    # L·∫∑p qua t·∫•t c·∫£ c√°c file trong th∆∞ m·ª•c ƒë·∫ßu v√†o\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(\".mp3\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            print(f\"\\n{'='*50}\\nProcessing file: {file_path}\\n{'='*50}\")\n",
    "\n",
    "            try:\n",
    "                # G·ªçi h√†m x·ª≠ l√Ω cho t·ª´ng file audio\n",
    "                final_srt = process_long_audio(\n",
    "                    file_path,\n",
    "                    chunk_length_ms=chunk_length_ms,\n",
    "                    target_bitrate=target_bitrate\n",
    "                )\n",
    "\n",
    "                # L∆∞u file SRT cu·ªëi c√πng v√†o c√πng th∆∞ m·ª•c\n",
    "                base_name = os.path.splitext(filename)[0]\n",
    "                output_file = os.path.join(input_folder, f\"{base_name}.srt\")\n",
    "                with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(final_srt)\n",
    "                print(f\"\\nSUCCESS: Full transcription for '{filename}' saved to {output_file}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\nERROR processing file {filename}: {e}\")\n",
    "                print(\"Skipping to the next file.\")\n",
    "                continue # B·ªè qua file n√†y v√† ti·∫øp t·ª•c v·ªõi file ti·∫øp theo\n",
    "\n",
    "    print(f\"\\n{'='*50}\\nAll .mp3 files have been processed.\\n{'='*50}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
