{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple srt file to wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# Set Google Cloud credentials (ensure the path is correct)\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"D:\\\\HI·∫æU\\\\plenary-agility-457810-t9-2bc80a805c4a.json\"\n",
    "\n",
    "\n",
    "input_folder = r\"C:\\Users\\Hieu Pham\\Downloads\\test\"  # input folder containing .srt files (batch processing).\n",
    "                                                   # Make sure only the required .srt files are inside this folder.\n",
    "input_language_srt = 'vi'  # language of the .srt file\n",
    "silence_ms = 1200 #silence from beginning of video to the first subtitle (milisecond). \n",
    "\n",
    "\n",
    "output_folder = input_folder\n",
    "output_voice = 'vi'  # note: distinguish between gtts and Google Cloud; gtts uses 'vi' while Google Cloud uses 'vi-VN'\n",
    "\n",
    "volume = 15\n",
    "speed = 1.5  # adjust individually; speaking rate depends on the language\n",
    "max_speed_limit = 2.3  # used to cap speed in case a sentence is too long for context\n",
    "\n",
    "max_duration_seconds = 1800  #maximum output file duration ‚Äî files longer than this will be split.\n",
    "                              # Used because free gtts has limits.\n",
    "\n",
    "start_index = 0  # default is 0. Use when the video is too long and gtts splits files according to max_duration_seconds.\n",
    "                  # This index is where subtitles should start after an undesired cut. \n",
    "                  # Do not rely on the index printed to the screen, it not true. Carefully align the .srt file with the audio.\n",
    "\n",
    "model = 'gtts'  # 'gtts' or 'google-cloud'\n",
    "voice_google_cloud = 'vi-VN-Neural2-A'  # Google Cloud only\n",
    "\n",
    "MAX_WORKERS = 20  # number of threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "from google.cloud import texttospeech\n",
    "from gtts import gTTS\n",
    "from dotenv import load_dotenv\n",
    "import traceback\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# --- NEW: custom exception for TTS API errors ---\n",
    "class TTSApiError(Exception):\n",
    "    def __init__(self, message, srt_idx=None):\n",
    "        super().__init__(message)\n",
    "        self.srt_idx = srt_idx\n",
    "\n",
    "# --- Core Functions (unchanged) ---\n",
    "def speed_up_audio_with_ffmpeg(input_audio_path, output_audio_path, speed_factor):\n",
    "    clamped_speed_factor = max(0.5, min(float(speed_factor), 100.0))\n",
    "    command = [\n",
    "        \"ffmpeg\", \"-y\", \"-i\", input_audio_path,\n",
    "        \"-filter:a\", f\"atempo={clamped_speed_factor}\",\n",
    "        \"-vn\", output_audio_path\n",
    "    ]\n",
    "    try:\n",
    "        result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"FFmpeg error ({input_audio_path}@{clamped_speed_factor}x): {e.stderr.decode()}\")\n",
    "        raise\n",
    "\n",
    "def parse_srt(srt_path):\n",
    "    with open(srt_path, 'r', encoding='utf-8') as f:\n",
    "        srt_text = f.read()\n",
    "    sections = re.split(r'\\n\\s*\\n', srt_text.strip())\n",
    "    parsed = []\n",
    "    for section in sections:\n",
    "        lines = section.strip().splitlines()\n",
    "        if len(lines) >= 3:\n",
    "            try:\n",
    "                index = int(lines[0])\n",
    "                times = lines[1]\n",
    "                start_time, end_time = times.split(' --> ')\n",
    "                text = ' '.join(lines[2:]).strip()\n",
    "                parsed.append((index, start_time, end_time, text))\n",
    "            except ValueError as e:\n",
    "                print(f\"Skipping malformed SRT section: {section}. Error: {e}\")\n",
    "    return parsed\n",
    "\n",
    "def srt_time_to_milliseconds(srt_time):\n",
    "    h, m, s_ms = srt_time.split(':')\n",
    "    s, ms = s_ms.split(',')\n",
    "    return (int(h) * 3600 + int(m) * 60 + int(s)) * 1000 + int(ms)\n",
    "\n",
    "\n",
    "# --- Modified: accept srt_idx for better error reporting ---\n",
    "def generate_audio_segment_with_google_tts_chunked(text, option=\"gtts\", language='vi',\n",
    "                                                 speed_factor_for_google_api=1.0,\n",
    "                                                 speed_factor_for_openai_api=1.0,\n",
    "                                                 volume_db=0, temp_file_id=\"temp\",\n",
    "                                                 google_voice_name=None, srt_idx=None):\n",
    "    base_temp_mp3 = f\"temp_{temp_file_id}.mp3\"\n",
    "    if not text.strip(): return AudioSegment.silent(duration=0)\n",
    "\n",
    "    if option == \"google_cloud\":\n",
    "        client = texttospeech.TextToSpeechClient()\n",
    "        synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "        voice = texttospeech.VoiceSelectionParams(language_code=language, name=(google_voice_name or 'en-US-Neural2-H'), ssml_gender=texttospeech.SsmlVoiceGender.FEMALE)\n",
    "        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3, speaking_rate=speed_factor_for_google_api, volume_gain_db=volume_db)\n",
    "        try:\n",
    "            response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
    "            with open(base_temp_mp3, 'wb') as out: out.write(response.audio_content)\n",
    "        except Exception as e:\n",
    "            # return silent previously; now raise so caller can stop and save\n",
    "            raise TTSApiError(f\"Google Cloud TTS error for '{text[:30]}...': {e}\", srt_idx)\n",
    "\n",
    "    elif option == \"gtts\":\n",
    "        try:\n",
    "            tts = gTTS(text=text, lang=language, slow=False)\n",
    "            tts.save(base_temp_mp3)\n",
    "        except Exception as e:\n",
    "            # IMPORTANT: raise instead of returning silent ‚Äî signal to stop whole run\n",
    "            raise TTSApiError(f\"gTTS error for '{text[:30]}...': {e}\", srt_idx)\n",
    "\n",
    "    elif option == \"openai\":\n",
    "        try:\n",
    "            client = OpenAI()\n",
    "            clamped_openai_speed = max(0.25, min(float(speed_factor_for_openai_api), 4.0))\n",
    "            with client.audio.speech.with_streaming_response.create(model='tts-1', voice='alloy', input=text, speed=clamped_openai_speed) as response:\n",
    "                response.stream_to_file(base_temp_mp3)\n",
    "        except Exception as e:\n",
    "            raise TTSApiError(f\"OpenAI TTS error for '{text[:30]}...': {e}\", srt_idx)\n",
    "    else:\n",
    "        raise ValueError(\"TTS Option must be 'google_cloud', 'gtts', or 'openai'.\")\n",
    "\n",
    "    segment = AudioSegment.silent(duration=0)\n",
    "    try:\n",
    "        if os.path.exists(base_temp_mp3) and os.path.getsize(base_temp_mp3) > 0:\n",
    "            segment = AudioSegment.from_mp3(base_temp_mp3)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading MP3 '{base_temp_mp3}' for '{text[:30]}...': {e}\")\n",
    "    finally:\n",
    "        if os.path.exists(base_temp_mp3): os.remove(base_temp_mp3)\n",
    "    return segment\n",
    "\n",
    "\n",
    "# --- Worker function (unchanged interface but pass srt_idx into TTS calls) ---\n",
    "def process_subtitle_to_final_audio(\n",
    "    text, srt_idx, tts_model, language,\n",
    "    initial_speed_factor,\n",
    "    target_srt_duration_ms,\n",
    "    volume_db,\n",
    "    speed_limit,\n",
    "    temp_file_id_prefix,\n",
    "    google_voice_name=None\n",
    "    ):\n",
    "    # Step 1: Initial TTS Generation\n",
    "    gen_args_initial = {\n",
    "        \"text\": text, \"option\": tts_model, \"language\": language,\n",
    "        \"temp_file_id\": f\"{temp_file_id_prefix}_initial\",\n",
    "        \"srt_idx\": srt_idx\n",
    "    }\n",
    "    if tts_model == \"google_cloud\":\n",
    "        gen_args_initial[\"speed_factor_for_google_api\"] = initial_speed_factor\n",
    "        gen_args_initial[\"volume_db\"] = volume_db\n",
    "        gen_args_initial[\"google_voice_name\"] = google_voice_name\n",
    "    elif tts_model == \"openai\":\n",
    "        gen_args_initial[\"speed_factor_for_openai_api\"] = initial_speed_factor\n",
    "\n",
    "    base_generated_segment = generate_audio_segment_with_google_tts_chunked(**gen_args_initial)\n",
    "    actual_raw_duration_ms = len(base_generated_segment)\n",
    "\n",
    "    if target_srt_duration_ms <= 0 and actual_raw_duration_ms > 0:\n",
    "        target_srt_duration_ms = actual_raw_duration_ms\n",
    "    elif target_srt_duration_ms <= 0 and actual_raw_duration_ms <= 0:\n",
    "        return AudioSegment.silent(duration=0)\n",
    "\n",
    "    final_segment_for_processing = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Step 2: Speed Adjustment\n",
    "    if actual_raw_duration_ms <= 0:\n",
    "        if target_srt_duration_ms > 0:\n",
    "            final_segment_for_processing = AudioSegment.silent(duration=target_srt_duration_ms)\n",
    "    elif tts_model == \"google_cloud\" or tts_model == \"openai\":\n",
    "        current_segment_from_api = base_generated_segment\n",
    "        api_speed_used_for_current_segment = initial_speed_factor\n",
    "\n",
    "        if actual_raw_duration_ms > target_srt_duration_ms and target_srt_duration_ms > 0:\n",
    "            required_api_speed = (actual_raw_duration_ms / target_srt_duration_ms) * api_speed_used_for_current_segment\n",
    "            api_speed_cap = 2.0\n",
    "            api_speed_floor = 0.25\n",
    "            final_api_speed_for_regen = max(api_speed_floor, min(required_api_speed, api_speed_cap))\n",
    "\n",
    "            regen_args = {\n",
    "                \"text\": text, \"option\": tts_model, \"language\": language,\n",
    "                \"temp_file_id\": f\"{temp_file_id_prefix}_regen\",\n",
    "                \"srt_idx\": srt_idx\n",
    "            }\n",
    "            if tts_model == \"google_cloud\":\n",
    "                regen_args[\"speed_factor_for_google_api\"] = final_api_speed_for_regen\n",
    "                regen_args[\"volume_db\"] = volume_db\n",
    "                regen_args[\"google_voice_name\"] = google_voice_name\n",
    "            elif tts_model == \"openai\":\n",
    "                regen_args[\"speed_factor_for_openai_api\"] = final_api_speed_for_regen\n",
    "\n",
    "            final_segment_for_processing = generate_audio_segment_with_google_tts_chunked(**regen_args)\n",
    "        else:\n",
    "            final_segment_for_processing = current_segment_from_api\n",
    "        \n",
    "        final_segment_for_processing = final_segment_for_processing[:target_srt_duration_ms]\n",
    "\n",
    "    elif tts_model == \"gtts\":\n",
    "        if target_srt_duration_ms <= 0:\n",
    "            final_segment_for_processing = base_generated_segment\n",
    "        else:\n",
    "            ffmpeg_speed_to_apply = 1.0\n",
    "            if (actual_raw_duration_ms / initial_speed_factor) <= target_srt_duration_ms:\n",
    "                ffmpeg_speed_to_apply = initial_speed_factor\n",
    "            else:\n",
    "                ffmpeg_speed_to_apply = actual_raw_duration_ms / target_srt_duration_ms\n",
    "            \n",
    "            ffmpeg_speed_to_apply = max(0.5, min(ffmpeg_speed_to_apply, speed_limit))\n",
    "\n",
    "            if abs(ffmpeg_speed_to_apply - 1.0) < 0.01:\n",
    "                final_segment_for_processing = base_generated_segment\n",
    "            else:\n",
    "                temp_raw_path = f\"temp_{temp_file_id_prefix}_gtts_raw.mp3\"\n",
    "                temp_sped_path = f\"temp_{temp_file_id_prefix}_gtts_sped.mp3\"\n",
    "                try:\n",
    "                    base_generated_segment.export(temp_raw_path, format=\"mp3\")\n",
    "                    speed_up_audio_with_ffmpeg(temp_raw_path, temp_sped_path, ffmpeg_speed_to_apply)\n",
    "                    final_segment_for_processing = AudioSegment.from_mp3(temp_sped_path)\n",
    "                except Exception as e_ffmpeg:\n",
    "                    print(f\"    Error in threaded gTTS FFmpeg for srt_idx {srt_idx}: {e_ffmpeg}. Using 1.0x audio.\")\n",
    "                    final_segment_for_processing = base_generated_segment\n",
    "                finally:\n",
    "                    if os.path.exists(temp_raw_path): os.remove(temp_raw_path)\n",
    "                    if os.path.exists(temp_sped_path): os.remove(temp_sped_path)\n",
    "        \n",
    "        final_segment_for_processing = final_segment_for_processing[:target_srt_duration_ms]\n",
    "\n",
    "    # Step 3: Padding\n",
    "    current_len = len(final_segment_for_processing)\n",
    "    if target_srt_duration_ms > current_len:\n",
    "        silence_needed_ms = target_srt_duration_ms - current_len\n",
    "        if silence_needed_ms > 0:\n",
    "            final_segment_for_processing += AudioSegment.silent(duration=silence_needed_ms)\n",
    "    \n",
    "    # Step 4: Volume\n",
    "    if tts_model == \"gtts\" or (tts_model == \"openai\" and volume_db != 0):\n",
    "        if volume_db != 0 and len(final_segment_for_processing) > 0:\n",
    "            final_segment_for_processing = final_segment_for_processing + volume_db\n",
    "            \n",
    "    return final_segment_for_processing\n",
    "\n",
    "\n",
    "def split_srt_into_chunks(parsed_srt, max_duration_seconds, start_index_filter=0):\n",
    "    max_duration_ms = max_duration_seconds * 1000\n",
    "    chunks = []\n",
    "    current_chunk_items = []\n",
    "    \n",
    "    first_relevant_srt_item_start_ms = None\n",
    "    if parsed_srt:\n",
    "        for srt_item_index_loop, start_time_str_loop, _, _ in parsed_srt:\n",
    "             if srt_item_index_loop >= start_index_filter:\n",
    "                 first_relevant_srt_item_start_ms = srt_time_to_milliseconds(start_time_str_loop)\n",
    "                 break\n",
    "    \n",
    "    if first_relevant_srt_item_start_ms is None and start_index_filter > 0 and parsed_srt:\n",
    "        return []\n",
    "\n",
    "    chunk_actual_start_time_ms = first_relevant_srt_item_start_ms if first_relevant_srt_item_start_ms is not None else 0\n",
    "\n",
    "    for srt_item_index, start_time_str, end_time_str, text_content in parsed_srt:\n",
    "        if srt_item_index < start_index_filter:\n",
    "            continue\n",
    "\n",
    "        start_ms = srt_time_to_milliseconds(start_time_str)\n",
    "        end_ms = srt_time_to_milliseconds(end_time_str)\n",
    "        current_item_srt_span_ms = end_ms - chunk_actual_start_time_ms\n",
    "\n",
    "        if current_item_srt_span_ms < 0: \n",
    "            print(f\"Skipping subtitle index {srt_item_index} due to inconsistent time.\")\n",
    "            continue\n",
    "        \n",
    "        if current_item_srt_span_ms > max_duration_ms and current_chunk_items:\n",
    "            chunks.append(list(current_chunk_items)) \n",
    "            current_chunk_items = [] \n",
    "            chunk_actual_start_time_ms = start_ms \n",
    "            current_item_srt_span_ms = end_ms - chunk_actual_start_time_ms \n",
    "\n",
    "        current_chunk_items.append((srt_item_index, start_ms, end_ms, text_content))\n",
    "        \n",
    "        if (end_ms - start_ms) > max_duration_ms and len(current_chunk_items) == 1:\n",
    "            chunks.append(list(current_chunk_items))\n",
    "            current_chunk_items = []\n",
    "            chunk_actual_start_time_ms = -1 \n",
    "\n",
    "    if current_chunk_items:\n",
    "        chunks.append(list(current_chunk_items))\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# --- Main Processing Logic with stop-on-gtts-error behavior ---\n",
    "def srt_to_audio(srt_path, output_path_prefix, input_lang_srt, output_lang_voice,\n",
    "                 initial_speed_factor_config, volume_adjustment_db_config,\n",
    "                 max_chunk_duration_sec, speed_limit_config,\n",
    "                 processing_start_index, tts_model_config, google_voice_name_config):\n",
    "    parsed_srt = parse_srt(srt_path)\n",
    "    if not parsed_srt:\n",
    "        print(f\"No subtitles parsed from {srt_path}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    srt_chunks = split_srt_into_chunks(parsed_srt, max_chunk_duration_sec, processing_start_index)\n",
    "    output_chunk_file_idx = 1\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        for chunk_num, current_chunk_items in enumerate(srt_chunks):\n",
    "            if not current_chunk_items: continue\n",
    "\n",
    "            chunk_srt_start_ms = current_chunk_items[0][1]\n",
    "            chunk_srt_end_ms = current_chunk_items[-1][2]\n",
    "            final_audio_chunk_total_duration_ms = chunk_srt_end_ms - chunk_srt_start_ms\n",
    "            \n",
    "            if final_audio_chunk_total_duration_ms <= 0:\n",
    "                print(f\"Skipping chunk {chunk_num+1} (to {output_chunk_file_idx}) due to zero/negative SRT duration ({final_audio_chunk_total_duration_ms}ms).\")\n",
    "                continue\n",
    "\n",
    "            final_audio_chunk = AudioSegment.silent(duration=final_audio_chunk_total_duration_ms)\n",
    "            last_subtitle_index_in_chunk = current_chunk_items[-1][0]\n",
    "\n",
    "            futures_map = {} # Maps future to {srt_idx, overlay_position_ms, srt_end_ms}\n",
    "            print(f\"\\nSubmitting tasks for audio chunk {output_chunk_file_idx} (SRTs up to {last_subtitle_index_in_chunk}) for '{os.path.basename(srt_path)}'...\")\n",
    "\n",
    "            for item_idx_in_chunk, (srt_idx, start_ms, end_ms, text) in enumerate(current_chunk_items):\n",
    "                if text.strip():\n",
    "                    task_info_for_map = {\n",
    "                        \"srt_idx\": srt_idx,\n",
    "                        \"overlay_position_ms\": start_ms - chunk_srt_start_ms,\n",
    "                        \"text_preview\": text[:20],\n",
    "                        \"srt_end_ms\": end_ms\n",
    "                    }\n",
    "                    target_duration_this_subtitle = end_ms - start_ms\n",
    "\n",
    "                    future = executor.submit(\n",
    "                        process_subtitle_to_final_audio,\n",
    "                        text=text,\n",
    "                        srt_idx=srt_idx,\n",
    "                        tts_model=tts_model_config,\n",
    "                        language=output_lang_voice,\n",
    "                        initial_speed_factor=initial_speed_factor_config,\n",
    "                        target_srt_duration_ms=target_duration_this_subtitle,\n",
    "                        volume_db=volume_adjustment_db_config,\n",
    "                        speed_limit=speed_limit_config,\n",
    "                        temp_file_id_prefix=f\"{os.path.splitext(os.path.basename(srt_path))[0]}_c{chunk_num}_s{srt_idx}\",\n",
    "                        google_voice_name=google_voice_name_config\n",
    "                    )\n",
    "                    futures_map[future] = task_info_for_map\n",
    "                else:\n",
    "                    target_dur_ms = end_ms - start_ms\n",
    "                    if target_dur_ms > 0:\n",
    "                        silent_segment = AudioSegment.silent(duration=target_dur_ms)\n",
    "                        final_audio_chunk = final_audio_chunk.overlay(\n",
    "                            silent_segment,\n",
    "                            position=(start_ms - chunk_srt_start_ms)\n",
    "                        )\n",
    "            \n",
    "            print(f\"  All {len(futures_map)} subtitle tasks for chunk {output_chunk_file_idx} submitted. Waiting for completion...\")\n",
    "\n",
    "            # Track last successful subtitle info so we can save up to it if a TTS error happens\n",
    "            last_successful_subtitle_idx = None\n",
    "            last_successful_subtitle_end_ms = None\n",
    "\n",
    "            try:\n",
    "                for future in as_completed(futures_map):\n",
    "                    task_info = futures_map[future]\n",
    "                    srt_idx_completed = task_info[\"srt_idx\"]\n",
    "                    try:\n",
    "                        processed_segment_for_subtitle = future.result()\n",
    "                        if len(processed_segment_for_subtitle) > 0:\n",
    "                            final_audio_chunk = final_audio_chunk.overlay(\n",
    "                                processed_segment_for_subtitle,\n",
    "                                position=task_info[\"overlay_position_ms\"]\n",
    "                            )\n",
    "                        # update last successful\n",
    "                        last_successful_subtitle_idx = srt_idx_completed\n",
    "                        last_successful_subtitle_end_ms = task_info[\"srt_end_ms\"]\n",
    "                    except TTSApiError as tts_err:\n",
    "                        # This is the critical case: stop processing, save chunk up to last_successful_subtitle_idx\n",
    "                        failing_idx = tts_err.srt_idx if tts_err.srt_idx is not None else srt_idx_completed\n",
    "                        print(f\"\\nCRITICAL: TTS API error at subtitle index {failing_idx}: {tts_err}\")\n",
    "                        # Save trimmed chunk up to last successful subtitle if any\n",
    "                        if last_successful_subtitle_idx is not None and last_successful_subtitle_end_ms is not None:\n",
    "                            # compute trimmed length relative to chunk start\n",
    "                            trimmed_len_ms = last_successful_subtitle_end_ms - chunk_srt_start_ms\n",
    "                            trimmed_chunk = final_audio_chunk[:trimmed_len_ms]\n",
    "                            output_audio_path = f\"{output_path_prefix}_chunk{output_chunk_file_idx}_endIdx{last_successful_subtitle_idx}.wav\"\n",
    "                            try:\n",
    "                                if len(trimmed_chunk) > 0:\n",
    "                                    trimmed_chunk.export(output_audio_path, format=\"wav\")\n",
    "                                    print(f\"SAVED PARTIAL: Audio chunk saved up to subtitle {last_successful_subtitle_idx} as '{os.path.basename(output_audio_path)}' (Duration: {len(trimmed_chunk)/1000:.2f}s).\")\n",
    "                                else:\n",
    "                                    print(\"No audio to save for partial chunk (trimmed length is zero).\")\n",
    "                            except Exception as e_export_partial:\n",
    "                                print(f\"Error exporting partial audio chunk '{output_audio_path}': {e_export_partial}\")\n",
    "                        else:\n",
    "                            print(\"No successful subtitle before error in this chunk; nothing to save for this chunk.\")\n",
    "                        # Re-raise to break outer processing and stop further chunks\n",
    "                        raise\n",
    "                    except Exception as e_task_complete:\n",
    "                        # Other exceptions ‚Äî log and continue processing other futures if possible\n",
    "                        print(f\"  Error in completed task result for subtitle index {srt_idx_completed} ('{task_info['text_preview']}...'): {e_task_complete}\")\n",
    "                        print(traceback.format_exc())\n",
    "\n",
    "            except TTSApiError:\n",
    "                # We already handled saving above; exit the function to stop processing subsequent chunks\n",
    "                print(\"Aborting further processing due to TTS API error.\")\n",
    "                return\n",
    "            except Exception as e_unhandled:\n",
    "                print(f\"Unhandled exception while processing futures for chunk {output_chunk_file_idx}: {e_unhandled}\")\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "            # If we got here, chunk processed normally (no fatal TTS error)\n",
    "            output_audio_path = f\"{output_path_prefix}_chunk{output_chunk_file_idx}_endIdx{last_subtitle_index_in_chunk}.wav\"\n",
    "            try:\n",
    "                if len(final_audio_chunk) > 0 :\n",
    "                    final_audio_chunk.export(output_audio_path, format=\"wav\")\n",
    "                    print(f\"SUCCESS: Audio chunk '{os.path.basename(output_audio_path)}' created (Duration: {len(final_audio_chunk)/1000:.2f}s).\")\n",
    "                else:\n",
    "                    print(f\"SKIPPED: Audio chunk '{os.path.basename(output_audio_path)}' would be empty.\")\n",
    "            except Exception as e_export:\n",
    "                print(f\"Error exporting audio chunk '{output_audio_path}': {e_export}\")\n",
    "            output_chunk_file_idx += 1\n",
    "\n",
    "\n",
    "# process_srt_folder remains the same, but keep passing google_voice_name_config correctly\n",
    "def process_srt_folder(root_input_folder, root_output_folder, lang_srt, lang_voice,\n",
    "                       base_speed, vol_db, chunk_duration_s, max_spd_limit, start_idx_filter, tts_engine, google_voice_name):\n",
    "    if not os.path.exists(root_input_folder):\n",
    "        print(f\"Error: Input folder '{root_input_folder}' does not exist.\")\n",
    "        return\n",
    "    if not os.path.exists(root_output_folder):\n",
    "        os.makedirs(root_output_folder)\n",
    "        print(f\"Created output folder: '{root_output_folder}'\")\n",
    "\n",
    "    for filename in os.listdir(root_input_folder):\n",
    "        if filename.endswith('.srt'):\n",
    "            srt_file_path = os.path.join(root_input_folder, filename)\n",
    "            sanitized_filename_base = re.sub(r'[^\\w\\-_]', '', os.path.splitext(filename)[0])\n",
    "            output_filename_prefix = os.path.join(root_output_folder, sanitized_filename_base)\n",
    "            \n",
    "            print(f\"\\n================ PROCESSING SRT: {filename} ================\")\n",
    "            srt_to_audio(\n",
    "                srt_path=srt_file_path, output_path_prefix=output_filename_prefix,\n",
    "                input_lang_srt=lang_srt, output_lang_voice=lang_voice,\n",
    "                initial_speed_factor_config=base_speed, volume_adjustment_db_config=vol_db,\n",
    "                max_chunk_duration_sec=chunk_duration_s, speed_limit_config=max_spd_limit,\n",
    "                processing_start_index=start_idx_filter, tts_model_config=tts_engine,\n",
    "                google_voice_name_config=google_voice_name\n",
    "            )\n",
    "\n",
    "# Example invocation (keep your existing variables)\n",
    "# process_srt_folder(...)\n",
    "\n",
    "\n",
    "\n",
    "process_srt_folder(\n",
    "    root_input_folder=input_folder, root_output_folder=output_folder,\n",
    "    lang_srt=input_language_srt, lang_voice=output_voice, base_speed=speed,\n",
    "    vol_db=volume, chunk_duration_s=max_duration_seconds, max_spd_limit=max_speed_limit,\n",
    "    start_idx_filter=start_index, tts_engine=model, google_voice_name=voice_google_cloud # <-- TH√äM D√íNG N√ÄY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n·ªëi wav    \n",
    "import os\n",
    "import re\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def concat_wavs(input_folder, silence_ms=0, output_filename=\"final.wav\"):\n",
    "    # Regex b·∫Øt s·ªë chunk gi·ªØa 2 d·∫•u _\n",
    "    chunk_pattern = re.compile(r'_(chunk\\d+)_')\n",
    "\n",
    "    def get_chunk_index(filename):\n",
    "        match = chunk_pattern.search(filename)\n",
    "        if match:\n",
    "            return int(re.search(r'\\d+', match.group(1)).group())  # l·∫•y s·ªë sau chunk\n",
    "        return float('inf')  # n·∫øu ko match th√¨ cho v·ªÅ cu·ªëi\n",
    "\n",
    "    # L·ªçc file wav\n",
    "    wav_files = [f for f in os.listdir(input_folder) if f.endswith(\".wav\")]\n",
    "    wav_files.sort(key=get_chunk_index)\n",
    "\n",
    "    final_audio = AudioSegment.silent(duration=0)\n",
    "    silence_segment = AudioSegment.silent(duration=silence_ms)\n",
    "\n",
    "    for wav_file in wav_files:\n",
    "        file_path = os.path.join(input_folder, wav_file)\n",
    "        audio = AudioSegment.from_wav(file_path)\n",
    "\n",
    "        # Th√™m silence v√†o ƒë·∫ßu m·ªói file\n",
    "        audio_with_silence = silence_segment + audio\n",
    "        final_audio += audio_with_silence\n",
    "\n",
    "        print(f\"ƒê√£ n·ªëi {wav_file}\")\n",
    "\n",
    "    # Xu·∫•t file cu·ªëi\n",
    "    output_path = os.path.join(input_folder, output_filename)\n",
    "    final_audio.export(output_path, format=\"wav\")\n",
    "    print(f\"‚úÖ ƒê√£ xu·∫•t file: {output_path}\")\n",
    "\n",
    "    # X√≥a c√°c file l·∫ª (tr·ª´ file final)\n",
    "    for wav_file in wav_files:\n",
    "        file_path = os.path.join(input_folder, wav_file)\n",
    "        if os.path.abspath(file_path) != os.path.abspath(output_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"üóëÔ∏è ƒê√£ x√≥a {wav_file}\")\n",
    "\n",
    "\n",
    "concat_wavs(input_folder, silence_ms=silence_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gh√©p mp4 v√† wav\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "def has_audio(video_path: str) -> bool:\n",
    "    \"\"\"Ki·ªÉm tra file mp4 c√≥ audio stream kh√¥ng b·∫±ng ffprobe\"\"\"\n",
    "    cmd = [\n",
    "        \"ffprobe\", \"-v\", \"error\",\n",
    "        \"-select_streams\", \"a\",\n",
    "        \"-show_entries\", \"stream=codec_type\",\n",
    "        \"-of\", \"json\",\n",
    "        video_path\n",
    "    ]\n",
    "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    info = json.loads(result.stdout)\n",
    "    return \"streams\" in info and len(info[\"streams\"]) > 0\n",
    "\n",
    "def merge_video_audio(folder_path: str):\n",
    "    files = os.listdir(folder_path)\n",
    "    mp4_files = [f for f in files if f.lower().endswith('.mp4')]\n",
    "    wav_files = [f for f in files if f.lower().endswith('.wav')]\n",
    "    \n",
    "    if len(mp4_files) != 1 or len(wav_files) != 1:\n",
    "        raise ValueError(\"Folder ph·∫£i ch·ª©a ƒë√∫ng 1 file MP4 v√† 1 file WAV\")\n",
    "\n",
    "    mp4_path = os.path.join(folder_path, mp4_files[0])\n",
    "    wav_path = os.path.join(folder_path, wav_files[0])\n",
    "    output_path = os.path.join(folder_path, \"final_video.mp4\")\n",
    "\n",
    "    if has_audio(mp4_path):\n",
    "        # Video c√≥ audio -> gi·∫£m volume video g·ªëc xu·ªëng 12% r·ªìi mix v·ªõi wav\n",
    "        cmd = [\n",
    "            \"ffmpeg\",\n",
    "            \"-i\", mp4_path,\n",
    "            \"-i\", wav_path,\n",
    "            \"-filter_complex\", \"[0:a]volume=0.12[a0];[a0][1:a]amix=inputs=2:duration=shortest[a]\",\n",
    "            \"-map\", \"0:v\",\n",
    "            \"-map\", \"[a]\",\n",
    "            \"-c:v\", \"copy\",\n",
    "            \"-c:a\", \"aac\",\n",
    "            \"-shortest\",\n",
    "            output_path,\n",
    "            \"-y\"\n",
    "        ]\n",
    "    else:\n",
    "        # Video kh√¥ng c√≥ audio -> g·∫Øn th·∫≥ng wav l√†m audio\n",
    "        cmd = [\n",
    "            \"ffmpeg\",\n",
    "            \"-i\", mp4_path,\n",
    "            \"-i\", wav_path,\n",
    "            \"-map\", \"0:v\",\n",
    "            \"-map\", \"1:a\",\n",
    "            \"-c:v\", \"copy\",\n",
    "            \"-c:a\", \"aac\",\n",
    "            \"-shortest\",\n",
    "            output_path,\n",
    "            \"-y\"\n",
    "        ]\n",
    "\n",
    "    subprocess.run(cmd, check=True)\n",
    "    \n",
    "# V√≠ d·ª• g·ªçi h√†m\n",
    "merge_video_audio(input_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
